{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1642afc-a89c-404b-8c3b-fd7b3b82d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os                                               # to set current working directory \n",
    "import sys                                              # supress output to screen for interactive variogram modeling\n",
    "import io\n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "from sklearn.model_selection import train_test_split    # train and test split\n",
    "from sklearn.metrics import mean_squared_error          # model error calculation\n",
    "from sklearn.preprocessing import StandardScaler        # standardize data\n",
    "import scipy                                            # kernel density estimator for PDF plot\n",
    "from matplotlib.pyplot import cm                        # color maps\n",
    "\n",
    "\n",
    "import tensorflow as tf                                 # build deep learning models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta\n",
    "\n",
    "\n",
    "from ipywidgets import interactive                      # widgets and interactivity\n",
    "from ipywidgets import widgets                            \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                       # supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b338ba3-3076-4e33-9e22-2172f75c1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "nreal  = 10\n",
    "seed = 42\n",
    "np.random.seed(seed)                                   # set seed for reproducibility\n",
    "\n",
    "activation_functions = ['linear', 'ReLU', 'Sigmoid', 'Softmax', 'Leaky ReLU', 'GELU']\n",
    "reduce_nodes = [True, False]\n",
    "node_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "epochs = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32]\n",
    "optimizers = ['SGD', 'Adam', 'Adadelta', 'RMSprop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d22a20e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5c552845a744d9b69944c2a4b31a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b>ðŸ“Š Data Parameters</b>'), IntSlider(value=30, description='Data Siâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# data parameters\n",
    "title_left = widgets.HTML(value=\"<b>ðŸ“Š Data Parameters</b>\")\n",
    "n = widgets.IntSlider(min=15, max=80, value=30, step=1, description='Data Size (n)', style={'description_width': 'initial'})\n",
    "split = widgets.FloatSlider(min=0.05, max=0.95, value=0.20, step=0.05, description='Test Split %', style={'description_width': 'initial'})\n",
    "std = widgets.FloatSlider(min=0, max=50, value=0, step=1.0, description='Noise StDev', style={'description_width': 'initial'})\n",
    "\n",
    "\n",
    "\n",
    "# Input layer parameters\n",
    "title_input = widgets.HTML(value=\"<b>ðŸ“¥ Input Layer</b>\")\n",
    "input_activation = widgets.Dropdown(options=['linear', 'ReLU', 'Sigmoid', 'Softmax', 'Leaky ReLU', 'GELU'],\n",
    "                                       value='ReLU', description='Activation')\n",
    "input_nodes = widgets.Dropdown(options=[1, 2, 4, 8, 16, 32, 64, 128], value=64, description='Nodes Per Layer')\n",
    "\n",
    "title_hidden = widgets.HTML(value=\"<b>ðŸ¤– Hidden Layers</b>\")\n",
    "hidden_activation = widgets.Dropdown(options=['linear', 'ReLU', 'Sigmoid', 'Softmax', 'Leaky ReLU', 'GELU'],\n",
    "                                       value='ReLU', description='Activation')\n",
    "reduce_nodes = widgets.ToggleButtons(options=[True, False], value=True, description='Reduce Nodes')\n",
    "hidden_nodes = widgets.Dropdown(options=[1, 2, 4, 8, 16, 32, 64, 128], value=64, description='Nodes Per Layer')\n",
    "num_hidden_layers = widgets.IntSlider(min=1, max=4, value=2, step=1, description='Num Hidden Layers')\n",
    "dropout_rate = widgets.FloatSlider(min=0.0, max=0.3, value=0.1, step=0.1, description='Dropout Rate')\n",
    "\n",
    "# ANN hyperparameters\n",
    "title_ann = widgets.HTML(value=\"<b>ðŸ§  ANN Parameters</b>\")\n",
    "epochs = widgets.Dropdown(options=[1, 2, 3, 4, 5, 10, 20, 50, 100], value=10, description='Epochs')\n",
    "learning_rate = widgets.Dropdown(options=[0.0001, 0.001, 0.01, 0.1], value=0.001, description='Learning Rate')\n",
    "batch_size = widgets.Dropdown(options=[1, 2, 4, 8, 16, 32], value=16, description='Batch Size')\n",
    "optimizer = widgets.Dropdown(options=['SGD', 'Adam', 'Adadelta', 'RMSprop'], value='Adam', description='Optimizer')\n",
    "\n",
    "data_column = widgets.VBox([title_left, n, split, std])\n",
    "input_column = widgets.VBox([title_input, input_activation, input_nodes])\n",
    "hidden_column = widgets.VBox([title_hidden, hidden_activation, hidden_nodes, num_hidden_layers, dropout_rate, reduce_nodes])\n",
    "ann_column = widgets.VBox([title_ann, epochs, learning_rate, batch_size, optimizer])\n",
    "\n",
    "\n",
    "# Combine into two-column layout\n",
    "ui = widgets.HBox([data_column, input_column, hidden_column, ann_column])\n",
    "# Display the UI\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bda767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(n: int, std: float, seed: int):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset based on a polynomial function with added noise.\n",
    "    \n",
    "    Parameters:\n",
    "    - n (int): Number of data points.\n",
    "    - split (float): Proportion of the dataset to include in the test split (e.g., 0.2 for 20% test data).\n",
    "    - std (float): Standard deviation of the Gaussian noise added to the data.\n",
    "    - seed (int): Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - X (array): Predictor feature values.\n",
    "    - y (array): Target values (response variable).\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)  # Seed the random number generator for reproducibility\n",
    "\n",
    "    # Generate dataset\n",
    "    X_seq = np.linspace(0, 20, 100)  # Sequence for plotting\n",
    "    X = np.random.rand(n) * 20  # Generate random X values within the range [0, 20]\n",
    "    \n",
    "    # Create polynomial target values (quadratic function in this case)\n",
    "    y = X ** 2 + 50.0  \n",
    "    \n",
    "    # Add Gaussian noise to the target variable\n",
    "    y += np.random.normal(loc=0.0, scale=std, size=n)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y, X_scaled\n",
    "\n",
    "\n",
    "\n",
    "def split_data(X, y, test_size=0.2, seed=42, realization=0):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    - X (array-like): Feature matrix.\n",
    "    - y (array-like): Target variable.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    - seed (int): Random seed for reproducibility.\n",
    "    - realization (int): Value added to the seed for multiple realizations.\n",
    "\n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Split training and testing datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=seed + realization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc183f21-a7ce-42ac-ad36-35d778932ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_layer(nodes: int, activation_function: str):\n",
    "    \"\"\"\n",
    "    Creates an input layer for a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    nodes (int): Number of neurons in the input layer.\n",
    "    activation_function (str): Activation function to be used in the input layer.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with the specified number of nodes and activation function.\n",
    "    \"\"\"\n",
    "    return Dense(nodes, activation=activation_function, input_shape=(1,))\n",
    "\n",
    "\n",
    "def hidden_layer(nodes: int, activation_function: str):\n",
    "    \"\"\"\n",
    "    Creates a hidden layer for a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    nodes (int): The number of neurons in the hidden layer.\n",
    "    activation_function (str): The activation function to be applied to the layer.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with the specified number of neurons and activation function.\n",
    "\n",
    "    Example:\n",
    "    >>> layer = hidden_layer(10, 'relu')\n",
    "    >>> print(layer)\n",
    "    <keras.src.layers.core.dense.Dense object at 0x...>\n",
    "    \"\"\"\n",
    "    return Dense(nodes, activation=activation_function)\n",
    "\n",
    "\n",
    "def output_layer():\n",
    "    \"\"\"\n",
    "    Creates an output layer for a neural network.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with one neuron and a linear activation function.\n",
    "    \"\"\"\n",
    "    return Dense(1, activation='linear')\n",
    "\n",
    "\n",
    "def create_hidden_layers(model, num_layers: int, start_nodes: int, reduce_nodes: bool, activation_function: str, dropout_rate: float):\n",
    "    \"\"\"\n",
    "    Adds hidden layers to a model with the option to either reduce or keep constant the number of neurons.\n",
    "\n",
    "    Parameters:\n",
    "    - model (Sequential): The Keras Sequential model to which the layers will be added.\n",
    "    - num_layers (int): Number of hidden layers to add.\n",
    "    - start_nodes (int): The number of neurons in the first hidden layer.\n",
    "    - reduce_nodes (bool): If True, the number of neurons will decrease in each layer.\n",
    "    - activation_function (str): The activation function to use for the hidden layers.\n",
    "\n",
    "    Returns:\n",
    "    - model (Sequential): The updated Keras Sequential model with added hidden layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        if reduce_nodes:\n",
    "            # Decrease the number of neurons by half in each layer\n",
    "            nodes = max(1, int(start_nodes / (2 ** i)))  # Avoid going below 1 neuron\n",
    "        else:\n",
    "            # Keep the number of neurons constant\n",
    "            nodes = start_nodes\n",
    "\n",
    "        model.add(hidden_layer(nodes, activation_function))\n",
    "        model.add(Dropout(dropout_rate))  # Add dropout layer\n",
    "        # Add a dropout layer after each hidden layer\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(input_nodes: int, input_activation: str,\n",
    "                num_hidden_layers: int, hidden_nodes: int, reduce_nodes: bool = True, hidden_activation: str = 'ReLU', dropout_rate: float = 0.0,\n",
    "                optimizer: str = 'adam', learning_rate: float = 0.01):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds a customizable neural network model using the Sequential API.\n",
    "\n",
    "    This function creates a neural network model with a specified number of hidden layers, \n",
    "    customizable hidden node sizes (with an option for reducing nodes), activation functions, \n",
    "    and dropout regularization.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_nodes : int\n",
    "        The number of nodes in the input layer.\n",
    "    \n",
    "    input_activation : str\n",
    "        The activation function for the input layer (e.g., 'ReLU', 'sigmoid', 'tanh').\n",
    "    \n",
    "    num_hidden_layers : int\n",
    "        The number of hidden layers to be added to the model.\n",
    "    \n",
    "    hidden_nodes : int\n",
    "        The number of nodes in the first hidden layer. The number of nodes in subsequent \n",
    "        layers will decrease if `reduce_nodes` is set to True.\n",
    "    \n",
    "    reduce_nodes : bool, default=True\n",
    "        Whether to reduce the number of nodes in each subsequent hidden layer. If False, \n",
    "        all hidden layers will have the same number of nodes as the first hidden layer.\n",
    "    \n",
    "    hidden_activation : str, default='ReLU'\n",
    "        The activation function for all hidden layers (e.g., 'ReLU', 'sigmoid', 'tanh').\n",
    "    \n",
    "    dropout_rate : float, default=0.0\n",
    "        The dropout rate applied to the hidden layers to prevent overfitting. A value between 0 and 1.\n",
    "\n",
    "    optimizer : str, default='adam'\n",
    "        The optimizer to use for training the model. Options include 'adam', 'sgd', 'adadelta', and 'rmsprop'.\n",
    "\n",
    "    learning_rate : float, default=0.01\n",
    "        The learning rate for the optimizer. This controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model : keras.Sequential\n",
    "        A compiled Sequential model ready to be trained.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    # Add the input layer\n",
    "    model.add(input_layer(input_nodes, input_activation))\n",
    "    # Add hidden layers\n",
    "    model = create_hidden_layers(model, num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate)\n",
    "    # Add the output layer\n",
    "    model.add(output_layer())\n",
    "\n",
    "    # Choose optimizer based on input\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Adadelta':\n",
    "        opt = Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, epochs: int = 10, batch_size: int = 32):\n",
    "    \"\"\"\n",
    "    Trains the neural network model on the provided training data.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : keras.Sequential\n",
    "        The compiled Keras model to be trained.\n",
    "    \n",
    "    X_train : np.ndarray\n",
    "        The input features for training.\n",
    "    \n",
    "    y_train : np.ndarray\n",
    "        The target variable for training.\n",
    "    \n",
    "    epochs : int, default=10\n",
    "        The number of epochs to train the model.\n",
    "    \n",
    "    batch_size : int, default=32\n",
    "        The size of the batches used in training.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    history : keras.callbacks.History\n",
    "        A History object containing details about the training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3375eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store MSE results\n",
    "mse_results = {\n",
    "    'node_sizes': np.zeros([len(node_sizes), nreal]),\n",
    "    'num_layers': np.zeros([len(num_layers), nreal]),\n",
    "    'dropout_rates': np.zeros([len(dropout_rates), nreal]),\n",
    "    'epochs_list': np.zeros([len(epochs), nreal]),\n",
    "    'learning_rates': np.zeros([len(learning_rates), nreal]),\n",
    "    'batch_sizes': np.zeros([len(batch_sizes), nreal])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_scaled = data_generator(n, std, seed)\n",
    "\n",
    "for j in range(nreal):\n",
    "    # Split data for each realization\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, split, seed, j)\n",
    "    \n",
    "    # Test different Input node sizes\n",
    "    for i, nodes in enumerate(node_sizes):\n",
    "        model = build_model(nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['node_sizes'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different Hidden node sizes\n",
    "    for i, nodes in enumerate(node_sizes):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['node_sizes'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different number of layers\n",
    "    for i, layers in enumerate(num_layers):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['num_layers'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different dropout rates\n",
    "    for i, dropout in enumerate(dropout_rates):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['dropout_rates'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different number of epochs\n",
    "    for i, epoch_value in enumerate(epochs_list):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epoch_value, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['epochs_list'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different learning rates\n",
    "    for i, lr in enumerate(learning_rates):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch_size)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['learning_rates'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Test different batch sizes\n",
    "    for i, batch in enumerate(batch_sizes):\n",
    "        model = build_model(input_nodes, input_activation,\n",
    "                num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate,\n",
    "                optimizer, learning_rate)\n",
    "        model = train_model(model, X_train, y_train, epochs, batch)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_results['batch_sizes'][i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# The mse_results dictionary now contains the MSE for each parameter across nreal realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c6884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e1433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db490989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4c54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640b66f-9a9c-494a-b982-1c560e173cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer, and custom learning rate\n",
    "optimizer = Adam(learning_rate=0.01)  # You can change the learning rate as needed\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model with custom batch size\n",
    "model.fit(X, y, epochs=100, batch_size=2, verbose=1)  # Using batch size of 2\n",
    "\n",
    "# Predict with the trained model\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions: \", predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfe3ea-3629-4c5b-9d94-6a3c05f2a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623881a5-c9ad-465a-a782-093550b34471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea37cc-7b08-4def-b699-af735a8f51a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a9b49-e5d0-4289-93ba-a859fa07e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822684b9-9876-4335-9418-fe3501891011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff184d-810a-471f-be9c-e04c8eb3d060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef58bd7-867f-4115-a88c-7b29f9418bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = widgets.Text(value='                                       Machine Learning Overfit/Generalization Demo, Prof. Michael Pyrcz and John Eric McCarthy II, The University of Texas at Austin',\n",
    "                 layout=Layout(width='950px', height='30px'))\n",
    "\n",
    "n = widgets.IntSlider(min=15, max = 80, value=30, step = 1, description = 'n',orientation='horizontal', style = {'description_width': 'initial'}, continuous_update=False)\n",
    "split = widgets.FloatSlider(min=0.05, max = .95, value=0.20, step = 0.05, description = 'Test %',orientation='horizontal',style = {'description_width': 'initial'}, continuous_update=False)\n",
    "std = widgets.FloatSlider(min=0, max = 50, value=0, step = 1.0, description = 'Noise StDev',orientation='horizontal',style = {'description_width': 'initial'}, continuous_update=False)\n",
    "degree = widgets.IntSlider(min=1, max = 12, value=1, step = 1, description = 'Model Order',orientation='horizontal', style = {'description_width': 'initial'}, continuous_update=False)\n",
    "\n",
    "ui = widgets.HBox([n,split,std,degree],)\n",
    "ui2 = widgets.VBox([l,ui],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
