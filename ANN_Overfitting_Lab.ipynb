{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1642afc-a89c-404b-8c3b-fd7b3b82d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os                                               # to set current working directory \n",
    "import sys                                              # supress output to screen for interactive variogram modeling\n",
    "import io\n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "from sklearn.model_selection import train_test_split    # train and test split\n",
    "from sklearn.metrics import mean_squared_error          # model error calculation\n",
    "from sklearn.preprocessing import StandardScaler        # standardize data\n",
    "import scipy                                            # kernel density estimator for PDF plot\n",
    "from matplotlib.pyplot import cm                        # color maps\n",
    "\n",
    "\n",
    "import tensorflow as tf                                 # build deep learning models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta\n",
    "\n",
    "\n",
    "from ipywidgets import interactive                      # widgets and interactivity\n",
    "from ipywidgets import widgets                            \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                       # supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b338ba3-3076-4e33-9e22-2172f75c1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = ['linear', 'ReLU', 'Sigmoid', 'Softmax', 'Leaky ReLU', 'GELU']\n",
    "reduce_nodes = [True, False]\n",
    "node_size = [2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "epochs = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "batch_size = [1, 2, 4, 8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc183f21-a7ce-42ac-ad36-35d778932ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_layer(nodes: int, activation_function: str):\n",
    "    \"\"\"\n",
    "    Creates an input layer for a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    nodes (int): Number of neurons in the input layer.\n",
    "    activation_function (str): Activation function to be used in the input layer.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with the specified number of nodes and activation function.\n",
    "    \"\"\"\n",
    "    return Dense(nodes, activation=activation_function, input_shape=(1,))\n",
    "\n",
    "\n",
    "def hidden_layer(nodes: int, activation_function: str):\n",
    "    \"\"\"\n",
    "    Creates a hidden layer for a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    nodes (int): The number of neurons in the hidden layer.\n",
    "    activation_function (str): The activation function to be applied to the layer.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with the specified number of neurons and activation function.\n",
    "\n",
    "    Example:\n",
    "    >>> layer = hidden_layer(10, 'relu')\n",
    "    >>> print(layer)\n",
    "    <keras.src.layers.core.dense.Dense object at 0x...>\n",
    "    \"\"\"\n",
    "    return Dense(nodes, activation=activation_function)\n",
    "\n",
    "\n",
    "def output_layer():\n",
    "    \"\"\"\n",
    "    Creates an output layer for a neural network.\n",
    "\n",
    "    Returns:\n",
    "    Dense: A Keras Dense layer with one neuron and a linear activation function.\n",
    "    \"\"\"\n",
    "    return Dense(1, activation='linear')\n",
    "\n",
    "\n",
    "def create_hidden_layers(model, num_layers: int, start_nodes: int, reduce_nodes: bool, activation_function: str, dropout_rate: float):\n",
    "    \"\"\"\n",
    "    Adds hidden layers to a model with the option to either reduce or keep constant the number of neurons.\n",
    "\n",
    "    Parameters:\n",
    "    - model (Sequential): The Keras Sequential model to which the layers will be added.\n",
    "    - num_layers (int): Number of hidden layers to add.\n",
    "    - start_nodes (int): The number of neurons in the first hidden layer.\n",
    "    - reduce_nodes (bool): If True, the number of neurons will decrease in each layer.\n",
    "    - activation_function (str): The activation function to use for the hidden layers.\n",
    "    \n",
    "    Returns:\n",
    "    - model (Sequential): The updated Keras Sequential model with added hidden layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        if reduce_nodes:\n",
    "            # Decrease the number of neurons by half in each layer\n",
    "            nodes = max(1, int(start_nodes / (2 ** i)))  # Avoid going below 1 neuron\n",
    "        else:\n",
    "            # Keep the number of neurons constant\n",
    "            nodes = start_nodes\n",
    "\n",
    "        model.add(hidden_layer(nodes, activation_function))\n",
    "        model.add(Dropout(dropout_rate))  # Add dropout layer\n",
    "        # Add a dropout layer after each hidden layer\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(input_nodes: int, input_activation: str,\n",
    "                num_hidden_layers: int, hidden_nodes: int, reduce_nodes: bool = True, hidden_activation: str = 'ReLU', dropout_rate: float = 0.0,\n",
    "                optimizer: str = 'adam', learning_rate: float = 0.01, batch_size: int = 32):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds a customizable neural network model using the Sequential API.\n",
    "\n",
    "    This function creates a neural network model with a specified number of hidden layers, \n",
    "    customizable hidden node sizes (with an option for reducing nodes), activation functions, \n",
    "    and dropout regularization.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_nodes : int\n",
    "        The number of nodes in the input layer.\n",
    "    \n",
    "    input_activation : str\n",
    "        The activation function for the input layer (e.g., 'ReLU', 'sigmoid', 'tanh').\n",
    "    \n",
    "    num_hidden_layers : int\n",
    "        The number of hidden layers to be added to the model.\n",
    "    \n",
    "    hidden_nodes : int\n",
    "        The number of nodes in the first hidden layer. The number of nodes in subsequent \n",
    "        layers will decrease if `reduce_nodes` is set to True.\n",
    "    \n",
    "    reduce_nodes : bool, default=True\n",
    "        Whether to reduce the number of nodes in each subsequent hidden layer. If False, \n",
    "        all hidden layers will have the same number of nodes as the first hidden layer.\n",
    "    \n",
    "    hidden_activation : str, default='ReLU'\n",
    "        The activation function for all hidden layers (e.g., 'ReLU', 'sigmoid', 'tanh').\n",
    "    \n",
    "    dropout_rate : float, default=0.0\n",
    "        The dropout rate applied to the hidden layers to prevent overfitting. A value between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model : keras.Sequential\n",
    "        A compiled Sequential model ready to be trained.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    # Add the input layer\n",
    "    model.add(input_layer(input_nodes, input_activation))\n",
    "    # Add hidden layers\n",
    "    model = create_hidden_layers(model, num_hidden_layers, hidden_nodes, reduce_nodes, hidden_activation, dropout_rate)\n",
    "    # Add the output layer\n",
    "    model.add(output_layer())\n",
    "\n",
    "    # Choose optimizer based on input\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640b66f-9a9c-494a-b982-1c560e173cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer, and custom learning rate\n",
    "optimizer = Adam(learning_rate=0.01)  # You can change the learning rate as needed\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model with custom batch size\n",
    "model.fit(X, y, epochs=100, batch_size=2, verbose=1)  # Using batch size of 2\n",
    "\n",
    "# Predict with the trained model\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions: \", predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfe3ea-3629-4c5b-9d94-6a3c05f2a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623881a5-c9ad-465a-a782-093550b34471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea37cc-7b08-4def-b699-af735a8f51a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a9b49-e5d0-4289-93ba-a859fa07e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822684b9-9876-4335-9418-fe3501891011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff184d-810a-471f-be9c-e04c8eb3d060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef58bd7-867f-4115-a88c-7b29f9418bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = widgets.Text(value='                                       Machine Learning Overfit/Generalization Demo, Prof. Michael Pyrcz and John Eric McCarthy II, The University of Texas at Austin',\n",
    "                 layout=Layout(width='950px', height='30px'))\n",
    "\n",
    "n = widgets.IntSlider(min=15, max = 80, value=30, step = 1, description = 'n',orientation='horizontal', style = {'description_width': 'initial'}, continuous_update=False)\n",
    "split = widgets.FloatSlider(min=0.05, max = .95, value=0.20, step = 0.05, description = 'Test %',orientation='horizontal',style = {'description_width': 'initial'}, continuous_update=False)\n",
    "std = widgets.FloatSlider(min=0, max = 50, value=0, step = 1.0, description = 'Noise StDev',orientation='horizontal',style = {'description_width': 'initial'}, continuous_update=False)\n",
    "degree = widgets.IntSlider(min=1, max = 12, value=1, step = 1, description = 'Model Order',orientation='horizontal', style = {'description_width': 'initial'}, continuous_update=False)\n",
    "\n",
    "ui = widgets.HBox([n,split,std,degree],)\n",
    "ui2 = widgets.VBox([l,ui],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
